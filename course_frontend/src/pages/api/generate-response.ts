import type { NextApiRequest, NextApiResponse } from 'next';
import fs from 'fs';
import path from 'path';

type ResponseData = {
  response: string;
  success: boolean;
  error?: string;
};

// Simulate a teacher client server response
// In production, this would actually call your LLM API 
const generateAIResponse = async (prompt: string, context: string): Promise<string> => {
  // This is a placeholder - in production, replace with actual LLM API call
  try {
    // Simulate API latency
    await new Promise(resolve => setTimeout(resolve, 1000));
    
    // Simple response generator - in real implementation, call your API
    if (prompt.length < 10) {
      return "Your prompt is quite short. Try to be more specific with your request to get better results.";
    }
    
    if (context.includes("Tone and Persona")) {
      return `Here's a response based on your prompt about tone and persona. Remember that setting the right tone and persona helps the AI understand how to communicate in a way that's appropriate for your audience.\n\nYour prompt: "${prompt}"\n\nThis is where the actual AI-generated content would appear, tailored to match the tone and persona you specified.`;
    }
    
    if (context.includes("Explicit Task")) {
      return `Here's a response based on your explicit task prompt. Clear, specific instructions help the AI generate exactly what you need.\n\nYour prompt: "${prompt}"\n\nThis is where the actual AI-generated content would appear, directly addressing the specific task you requested.`;
    }
    
    return `Here's a response to your prompt: "${prompt}"\n\nIn a production environment, this would be generated by an actual LLM based on your request, considering the context of ${context}.`;
  } catch (error) {
    console.error('Error generating AI response:', error);
    return "Sorry, there was an error generating a response. Please try again.";
  }
};

// Store prompts for future evaluation
const storePrompt = async (prompt: string, response: string, context: string) => {
  try {
    const promptData = {
      timestamp: new Date().toISOString(),
      prompt,
      response,
      context,
    };
    
    // Create directory if it doesn't exist
    const dataDir = path.join(process.cwd(), 'data');
    if (!fs.existsSync(dataDir)) {
      fs.mkdirSync(dataDir, { recursive: true });
    }
    
    // Append to prompts log file
    const promptsFile = path.join(dataDir, 'prompts.json');
    let prompts = [];
    
    if (fs.existsSync(promptsFile)) {
      const fileContent = fs.readFileSync(promptsFile, 'utf8');
      prompts = JSON.parse(fileContent);
    }
    
    prompts.push(promptData);
    fs.writeFileSync(promptsFile, JSON.stringify(prompts, null, 2));
    
    return true;
  } catch (error) {
    console.error('Error storing prompt:', error);
    return false;
  }
};

export default async function handler(
  req: NextApiRequest,
  res: NextApiResponse<ResponseData>
) {
  if (req.method !== 'POST') {
    return res.status(405).json({ success: false, response: 'Method not allowed', error: 'Only POST requests are allowed' });
  }

  try {
    const { prompt, context } = req.body;
    
    if (!prompt || typeof prompt !== 'string') {
      return res.status(400).json({ success: false, response: 'Invalid request', error: 'Prompt is required and must be a string' });
    }
    
    // Generate response from the prompt
    const response = await generateAIResponse(prompt, context || 'general');
    
    // Store the prompt and response
    await storePrompt(prompt, response, context || 'general');
    
    return res.status(200).json({ success: true, response });
  } catch (error) {
    console.error('API route error:', error);
    return res.status(500).json({ 
      success: false, 
      response: 'Server error', 
      error: 'Failed to process your request' 
    });
  }
} 